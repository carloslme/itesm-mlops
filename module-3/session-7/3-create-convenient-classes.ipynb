{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aqyoDIrmbA4O"},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elp0Ya-qbA4T"},"outputs":[],"source":["DATASETS_DIR = 'datasets/'\n","URL = 'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'\n","DROP_COLS = ['boat','body','home.dest','ticket','name']\n","RETRIEVED_DATA = 'raw-data.csv'\n","\n","\n","SEED_SPLIT = 404\n","TRAIN_DATA_FILE = DATASETS_DIR + 'train.csv'\n","TEST_DATA_FILE  = DATASETS_DIR + 'test.csv'\n","\n","\n","TARGET = 'survived'\n","FEATURES = ['pclass','sex','age','sibsp','parch','fare','cabin','embarked','title']\n","NUMERICAL_VARS = ['pclass','age','sibsp','parch','fare']\n","CATEGORICAL_VARS = ['sex','cabin','embarked','title']\n","\n","\n","NUMERICAL_VARS_WITH_NA = ['age','fare']\n","CATEGORICAL_VARS_WITH_NA = ['cabin','embarked']\n","NUMERICAL_NA_NOT_ALLOWED = [var for var in NUMERICAL_VARS if var not in NUMERICAL_VARS_WITH_NA]\n","CATEGORICAL_NA_NOT_ALLOWED = [var for var in CATEGORICAL_VARS if var not in CATEGORICAL_VARS_WITH_NA]\n","\n","\n","SEED_MODEL = 404"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAtmWQjnbA4U"},"outputs":[],"source":["def data_retrieval(url):\n","\n","    # Loading data from specific url\n","    data = pd.read_csv(url)\n","\n","    # Uncovering missing data\n","    data.replace('?', np.nan, inplace=True)\n","    data['age'] = data['age'].astype('float')\n","    data['fare'] = data['fare'].astype('float')\n","\n","    # helper function 1\n","    def get_first_cabin(row):\n","        try:\n","            return row.split()[0]\n","        except:\n","            return np.nan\n","\n","    # helper function 2\n","    def get_title(passenger):\n","        line = passenger\n","        if re.search('Mrs', line):\n","            return 'Mrs'\n","        elif re.search('Mr', line):\n","            return 'Mr'\n","        elif re.search('Miss', line):\n","            return 'Miss'\n","        elif re.search('Master', line):\n","            return 'Master'\n","        else:\n","            return 'Other'\n","\n","    # Keep only one cabin | Extract the title from 'name'\n","    data['cabin'] = data['cabin'].apply(get_first_cabin)\n","    data['title'] = data['name'].apply(get_title)\n","\n","    # Droping irrelevant columns\n","    data.drop(DROP_COLS, 1, inplace=True)\n","\n","    data.to_csv(DATASETS_DIR + RETRIEVED_DATA, index=False)\n","\n","    return print('Data stored in {}'.format(DATASETS_DIR + RETRIEVED_DATA))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ej4TXXV2bA4V","outputId":"84923f9e-5b58-4cbc-87d0-41bed924c284"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data stored in datasets/raw-data.csv\n"]}],"source":["data_retrieval(URL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttJd7QySbA4W"},"outputs":[],"source":["df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6bzhGmabA4X"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","                                                        df.drop(TARGET, axis=1),\n","                                                        df[TARGET],\n","                                                        test_size=0.2,\n","                                                        random_state=404\n","                                                   )\n","\n","X_train.to_csv(TRAIN_DATA_FILE, index=False)\n","X_test.to_csv(TEST_DATA_FILE, index=False)\n","y_test.to_csv('y_test.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"qL7qPTdGbA4Y"},"source":["___\n","## Creating convenient classes"]},{"cell_type":"markdown","metadata":{"id":"0wH0G8pabA4Z"},"source":["### Transformations without persisting information"]},{"cell_type":"markdown","metadata":{"id":"aPaDt_STbA4a"},"source":["**Before**\n","\n","```python\n","def missing_indicator(data, col_name):\n","    data[col_name+'_nan'] = data[col_name].isnull().astype(int)\n","    return None\n","\n","for var in NUMERICAL_VARS:\n","    missing_indicator(X_train, var)\n","    missing_indicator(X_test, var)\n","```\n","\n","**Now**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkCQd91cbA4a"},"outputs":[],"source":["class MissingIndicator(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var+'_nan'] = X[var].isnull().astype(int)\n","\n","        return X\n","\n","\n","create_missing_flag = MissingIndicator(variables=NUMERICAL_VARS)\n","X_train = create_missing_flag.transform(X_train)\n","X_test = create_missing_flag.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"M8OtJ3z_bA4b"},"source":["**Before**\n","\n","```python\n","def extract_letter_from_cabin(x):\n","    if type(x)==str:    \n","        return ''.join(re.findall(\"[a-zA-Z]+\", x))  \n","    else:\n","        return x\n","\n","X_train['cabin'] = X_train['cabin'].apply(extract_letter_from_cabin)    \n","X_test['cabin'] = X_test['cabin'].apply(extract_letter_from_cabin)    \n","\n","X_train[CATEGORICAL_VARS_WITH_NA] = X_train[CATEGORICAL_VARS_WITH_NA].fillna('missing')\n","X_test[CATEGORICAL_VARS_WITH_NA]  = X_test[CATEGORICAL_VARS_WITH_NA].fillna('missing')\n","```\n","\n","**Now**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh7hhAeEbA4b"},"outputs":[],"source":["class ExtractLetters(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self):\n","        self.variable = 'cabin'\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        X[self.variable] = X[self.variable].apply(lambda x: ''.join(re.findall(\"[a-zA-Z]+\", x)) if type(x)==str else x)\n","        return X\n","\n","\n","class CategoricalImputer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var] = X[var].fillna('Missing')\n","        return X\n","\n","\n","extract_letters_cabin = ExtractLetters()\n","X_train = extract_letters_cabin.transform(X_train)\n","X_test = extract_letters_cabin.transform(X_test)\n","\n","categ_imputer = CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)\n","X_train = categ_imputer.transform(X_train)\n","X_test = categ_imputer.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"NFfIzPTSbA4c"},"source":["### Transformations with persisting information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNzeqABrbA4c"},"outputs":[],"source":["imp_median = SimpleImputer(strategy='median')\n","imp_median.fit(X_train[NUMERICAL_VARS_WITH_NA])\n","\n","X_train[NUMERICAL_VARS_WITH_NA] = imp_median.transform(X_train[NUMERICAL_VARS_WITH_NA])\n","X_test[NUMERICAL_VARS_WITH_NA]  = imp_median.transform(X_test[NUMERICAL_VARS_WITH_NA])"]},{"cell_type":"markdown","metadata":{"id":"3GY2iLGcbA4c"},"source":["**Before**\n","\n","```python\n","def find_rare_labels(data, col, perc):\n","    data = data.copy()\n","    tmp = data.groupby(col)[col].count() / data.shape[0]\n","    return tmp[tmp < perc].index\n","\n","rare_labels_ = {}\n","for col in CATEGORICAL_VARS:\n","    rare_labels_[col] = find_rare_labels(X_train, col, 0.05)\n","    \n","for col in CATEGORICAL_VARS:\n","    X_train[col] = np.where(X_train[col].isin(rare_labels_[col]), 'Rare', X_train[col])\n","    X_test[col]  = np.where(X_test[col].isin(rare_labels_[col]), 'Rare', X_test[col])\n","```\n","\n","**Now**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMvTWZ5wbA4d"},"outputs":[],"source":["class RareLabelCategoricalEncoder(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, tol=0.05, variables=None):\n","        self.tol = tol\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        self.rare_labels_dict = {}\n","        for var in self.variables:\n","            t = pd.Series(X[var].value_counts() / np.float(X.shape[0]))\n","            self.rare_labels_dict[var] = list(t[t<self.tol].index)\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var] = np.where(X[var].isin(self.rare_labels_dict[var]), 'rare', X[var])\n","        return X\n","\n","\n","rare_labels = RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)\n","rare_labels.fit(X_train)\n","X_train = rare_labels.transform(X_train)\n","X_test  = rare_labels.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"QeLovJBRbA4d"},"source":["**Before**\n","\n","```python\n","X_train = pd.concat([X_train, pd.get_dummies(X_train[CATEGORICAL_VARS], drop_first=True)], 1)\n","X_test  = pd.concat([X_test, pd.get_dummies(X_test[CATEGORICAL_VARS], drop_first=True)], 1)\n","\n","X_train.drop(CATEGORICAL_VARS, 1, inplace=True)\n","X_test.drop(CATEGORICAL_VARS, 1, inplace=True)\n","\n","# Validation step\n","set(X_train.columns).difference(set(X_test.columns))\n","\n","for col in list(set(X_train.columns).difference(set(X_test.columns))):\n","    X_test[col] = 0\n","```\n","\n","**Now**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zoiQUYaVbA4e"},"outputs":[],"source":["class OneHotEncoder(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        X = pd.concat([X, pd.get_dummies(X[self.variables], drop_first=True)], 1)\n","        X.drop(self.variables, 1, inplace=True)\n","\n","        # Adding missing dummies, if any\n","        missing_dummies = [var for var in self.dummies if var not in X.columns]\n","        if len(missing_dummies) != 0:\n","            for col in missing_dummies:\n","                X[col] = 0\n","\n","        return X\n","\n","\n","dummy_vars = OneHotEncoder(variables=CATEGORICAL_VARS)\n","dummy_vars.fit(X_train)\n","X_train = dummy_vars.transform(X_train)\n","X_test  = dummy_vars.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"Pkk-hcxBbA4e"},"source":["**Aligning columns of X_train and X_test**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ylkHn_BpbA4e"},"outputs":[],"source":["class OrderingFeatures(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        return None\n","\n","    def fit(self, X, y=None):\n","        self.ordered_features = X.columns\n","        return self\n","\n","    def transform(self, X):\n","        return X[self.ordered_features]\n","\n","\n","sort_feats = OrderingFeatures()\n","sort_feats.fit(X_train)\n","X_train = sort_feats.transform(X_train)\n","X_test  = sort_feats.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"raRSDYq4bA4f"},"source":["**Scaling**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bk5fPFSvbA4f"},"outputs":[],"source":["scaler = MinMaxScaler()\n","scaler.fit(X_train)\n","\n","X_train = scaler.transform(X_train)\n","X_test  = scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"XkSFkY0MbA4f"},"source":["___"]},{"cell_type":"markdown","metadata":{"id":"8u3DLjyQbA4g"},"source":["## 4. Training model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lzkjqb3ZbA4g","outputId":"c26cf86d-3f39-4911-ca89-8a0c04cd40de"},"outputs":[{"data":{"text/plain":["LogisticRegression(C=0.0005, class_weight='balanced', dual=False,\n","                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n","                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=404, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model = LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL)\n","model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"n6r8Jy7ubA4g"},"source":["- train roc-auc : 0.8470412710714978\n","- train accuracy: 0.7831900668576887\n","\n","- test roc-auc : 0.8163583073823043\n","- test accuracy: 0.7748091603053435"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5f9hHnLbA4g","outputId":"d330b750-f6ce-4100-ae8d-f4bb072909b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["train roc-auc : 0.8470412710714978\n","train accuracy: 0.7831900668576887\n","\n","test roc-auc : 0.8163583073823043\n","test accuracy: 0.7748091603053435\n","\n"]}],"source":["for s,t in zip(['train','test'],[(X_train, y_train),(X_test,y_test)]):\n","    x,y = t[0], t[1]\n","    class_pred = model.predict(x)\n","    proba_pred = model.predict_proba(x)[:,1]\n","    print('{} roc-auc : {}'.format(s, roc_auc_score(y, proba_pred)))\n","    print('{} accuracy: {}'.format(s, accuracy_score(y, class_pred)))\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56CGo7ElbA4g","outputId":"770e3d32-c82a-4203-bd09-c95abf233ac9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>pclass_nan</th>\n","      <th>age_nan</th>\n","      <th>sibsp_nan</th>\n","      <th>parch_nan</th>\n","      <th>fare_nan</th>\n","      <th>...</th>\n","      <th>cabin_rare</th>\n","      <th>embarked_Q</th>\n","      <th>embarked_S</th>\n","      <th>embarked_rare</th>\n","      <th>title_Mr</th>\n","      <th>title_Mrs</th>\n","      <th>title_rare</th>\n","      <th>y_true</th>\n","      <th>y_pred</th>\n","      <th>proba_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.724426</td>\n","      <td>0.000</td>\n","      <td>0.222222</td>\n","      <td>0.221098</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.502177</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.5</td>\n","      <td>0.386221</td>\n","      <td>0.125</td>\n","      <td>0.111111</td>\n","      <td>0.051237</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.481497</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.223382</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.015379</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.513358</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.5</td>\n","      <td>0.423799</td>\n","      <td>0.125</td>\n","      <td>0.000000</td>\n","      <td>0.040989</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.481422</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.5</td>\n","      <td>0.486430</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.050749</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.481452</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","      <td>0.298538</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.013940</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.477030</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.5</td>\n","      <td>0.160751</td>\n","      <td>0.000</td>\n","      <td>0.111111</td>\n","      <td>0.038061</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.514231</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>0.611691</td>\n","      <td>0.125</td>\n","      <td>0.000000</td>\n","      <td>0.111118</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.501921</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.0</td>\n","      <td>0.398747</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.148911</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.534687</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.0</td>\n","      <td>0.260960</td>\n","      <td>0.250</td>\n","      <td>0.222222</td>\n","      <td>0.512122</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.531581</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 23 columns</p>\n","</div>"],"text/plain":["   pclass       age  sibsp     parch      fare  pclass_nan  age_nan  \\\n","0     0.0  0.724426  0.000  0.222222  0.221098         0.0      0.0   \n","1     0.5  0.386221  0.125  0.111111  0.051237         0.0      0.0   \n","2     1.0  0.223382  0.000  0.000000  0.015379         0.0      0.0   \n","3     0.5  0.423799  0.125  0.000000  0.040989         0.0      0.0   \n","4     0.5  0.486430  0.000  0.000000  0.050749         0.0      0.0   \n","5     1.0  0.298538  0.000  0.000000  0.013940         0.0      0.0   \n","6     0.5  0.160751  0.000  0.111111  0.038061         0.0      0.0   \n","7     0.0  0.611691  0.125  0.000000  0.111118         0.0      0.0   \n","8     0.0  0.398747  0.000  0.000000  0.148911         0.0      0.0   \n","9     0.0  0.260960  0.250  0.222222  0.512122         0.0      0.0   \n","\n","   sibsp_nan  parch_nan  fare_nan  ...  cabin_rare  embarked_Q  embarked_S  \\\n","0        0.0        0.0       0.0  ...         1.0         0.0         0.0   \n","1        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","2        0.0        0.0       0.0  ...         0.0         1.0         0.0   \n","3        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","4        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","5        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","6        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","7        0.0        0.0       0.0  ...         1.0         0.0         0.0   \n","8        0.0        0.0       0.0  ...         1.0         0.0         0.0   \n","9        0.0        0.0       0.0  ...         0.0         0.0         0.0   \n","\n","   embarked_rare  title_Mr  title_Mrs  title_rare  y_true  y_pred  proba_pred  \n","0            0.0       1.0        0.0         0.0       0       1    0.502177  \n","1            0.0       1.0        0.0         0.0       0       0    0.481497  \n","2            0.0       0.0        0.0         0.0       0       1    0.513358  \n","3            0.0       1.0        0.0         0.0       0       0    0.481422  \n","4            0.0       1.0        0.0         0.0       0       0    0.481452  \n","5            0.0       1.0        0.0         0.0       1       0    0.477030  \n","6            0.0       0.0        0.0         0.0       1       1    0.514231  \n","7            0.0       1.0        0.0         0.0       1       1    0.501921  \n","8            0.0       0.0        0.0         0.0       1       1    0.534687  \n","9            0.0       0.0        0.0         0.0       1       1    0.531581  \n","\n","[10 rows x 23 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["tmp = pd.DataFrame(X_test, columns=list(sort_feats.ordered_features))\n","tmp['y_true'] = np.array(y_test)\n","tmp['y_pred'] = model.predict(X_test)\n","tmp['proba_pred'] = model.predict_proba(X_test)[:,1]\n","\n","tmp.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMDr2azgbA4h"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}