{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "The code is for downloading the data from the URL to not dwell on it. First, we imported the os module for interacting with the Operating System. After that, we imported the tarfile module for accessing and manipulating tar files. Lastly, we imported the urllib for using URL manipulation functions.\n",
    "\n",
    "Then, we set our paths appropriately. In the get_data() function, we made a directory for our data, retrieved it from the URL then extracted and stored it.\n",
    "\n",
    "So, in your working directory, you will notice a directory called datasets created. On opening it, you will get another directory called housing with a file named housing.csv in it. We will use this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "OUR_ROOT_URL = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "OUR_PATH = \"datasets/housing\"\n",
    "OUR_DATA_URL = OUR_ROOT_URL + OUR_PATH + \"/housing.tgz\"\n",
    "\n",
    "def get_data(our_data_url=OUR_DATA_URL, our_path=OUR_PATH):\n",
    "      if not os.path.isdir(our_path):\n",
    "            os.makedirs(our_path)\n",
    "      #setting the zip file path      \n",
    "      zipfile_path = os.path.join(our_path, \"housing.tgz\")\n",
    "      #getting the file from the url and extracting it\n",
    "      urllib.request.urlretrieve(our_data_url, zipfile_path)\n",
    "      our_zip_file = tarfile.open(zipfile_path)\n",
    "      our_zip_file.extractall(path=our_path)\n",
    "      our_zip_file.close()\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_our_data(our_path=OUR_PATH):\n",
    "    #setting the csv file path\n",
    "    our_file_path = os.path.join(our_path, \"housing.csv\")\n",
    "    #reading it using Pandas\n",
    "    return pd.read_csv(our_file_path)\n",
    "\n",
    "our_dataset = load_our_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "our_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "The cleaning operation we will do here is filling empty numeric attributes with their median values. We will use the SimpleImputer, an estimator, to do that. But, first, we set the strategy to median to calculate the median value for each column’s empty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "'''setting the `strategy` to `median` so that it calculates the median value for each column's empty data'''\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "#removing the ocean_proximity attribute for it is textual\n",
    "our_dataset_num = our_dataset.drop(\"ocean_proximity\", axis=1)\n",
    "#estimation using the fit method\n",
    "imputer.fit(our_dataset_num)\n",
    "#transforming using the learnedparameters\n",
    "X = imputer.transform(our_dataset_num)\n",
    "#setting the transformed dataset to a DataFrame\n",
    "our_dataset_numeric = pd.DataFrame(X, columns=our_dataset_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped the ocean_proximity attribute because it’s a text attribute that will handle in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling text and categorical attributes\n",
    "We cannot handle text and numerical attributes similarly. So, for example, we cannot compute the median of text.\n",
    "\n",
    "We will use a transformer for this called the OrdinalEncoder. It is chosen because it is more pipeline friendly. Moreover, it assigns numbers to the corresponding text attributes, e.g., 1 for NEAR and 2 for FAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#selecting the textual attribute\n",
    "our_text_cats = our_dataset[['ocean_proximity']]\n",
    "our_encoder = OrdinalEncoder()\n",
    "#transforming it\n",
    "our_encoded_dataset = our_encoder.fit_transform(our_text_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformer\n",
    "This is where we will create the custom transformer. We will be adding these three attributes:\n",
    "\n",
    "* Rooms per household.\n",
    "* Population per household.\n",
    "* Bedrooms per household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#initialising column numbers\n",
    "rooms,  bedrooms, population, household = 3,4,5,6\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    #the constructor\n",
    "    '''setting the add_bedrooms_per_room to True helps us check if the hyperparameter is useful'''\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    #estimator method\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    #transfprmation\n",
    "    def transform(self, X, y = None):\n",
    "        #getting the three extra attributes by dividing appropriate attributes\n",
    "        rooms_per_household = X[:, rooms] / X[:, household]\n",
    "        population_per_household = X[:, population] / X[:, household]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms] / X[:, rooms]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attrib_adder = CustomTransformer()\n",
    "our_extra_attributes = attrib_adder.transform(our_dataset.values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-122.23, 37.88, 41.0, ..., 6.984126984126984, 2.5555555555555554,\n",
       "        0.14659090909090908],\n",
       "       [-122.22, 37.86, 21.0, ..., 6.238137082601054, 2.109841827768014,\n",
       "        0.15579659106916466],\n",
       "       [-122.24, 37.85, 52.0, ..., 8.288135593220339, 2.8022598870056497,\n",
       "        0.12951601908657123],\n",
       "       ...,\n",
       "       [-121.22, 39.43, 17.0, ..., 5.20554272517321, 2.325635103926097,\n",
       "        0.21517302573203195],\n",
       "       [-121.32, 39.43, 18.0, ..., 5.329512893982808, 2.1232091690544412,\n",
       "        0.21989247311827956],\n",
       "       [-121.24, 39.37, 16.0, ..., 5.254716981132075, 2.616981132075472,\n",
       "        0.22118491921005387]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_extra_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#the numeric attributes transformation pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CustomTransformer()),\n",
    "    ])\n",
    "numeric_attribs = list(our_dataset_numeric)\n",
    "#the textual transformation pipeline\n",
    "text_attribs = [\"ocean_proximity\"]\n",
    "#setting the order of the two pipelines\n",
    "our_full_pipeline = ColumnTransformer([\n",
    "        (\"numeric\", numeric_pipeline, numeric_attribs),\n",
    "        (\"text\", OrdinalEncoder(), text_attribs),\n",
    "    ])\n",
    "'''Finally, scaling the data and learning the scaled parameters from the pipeline\n",
    "'''\n",
    "our_dataset_prepared = our_full_pipeline.fit_transform(our_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-122.23      ,   37.88      ,   41.        , ...,    2.55555556,\n",
       "           0.14659091,    3.        ],\n",
       "       [-122.22      ,   37.86      ,   21.        , ...,    2.10984183,\n",
       "           0.15579659,    3.        ],\n",
       "       [-122.24      ,   37.85      ,   52.        , ...,    2.80225989,\n",
       "           0.12951602,    3.        ],\n",
       "       ...,\n",
       "       [-121.22      ,   39.43      ,   17.        , ...,    2.3256351 ,\n",
       "           0.21517303,    1.        ],\n",
       "       [-121.32      ,   39.43      ,   18.        , ...,    2.12320917,\n",
       "           0.21989247,    1.        ],\n",
       "       [-121.24      ,   39.37      ,   16.        , ...,    2.61698113,\n",
       "           0.22118492,    1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_dataset_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_dataset_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* https://github.com/carloslme/handson-ml2-book/blob/main/02_end_to_end_machine_learning_project.ipynb\n",
    "* https://www.section.io/engineering-education/custom-transformer\n",
    "* https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
