{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n",
        "In this notebook section, we will import the libraries needed to run this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9wFRz2IbzBua"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constant Variables\n",
        "In a Jupyter Notebook, creating constant variables can be important for several reasons:\n",
        "\n",
        "* **Readability and Maintainability**: Using constant variables with meaningful names can improve the readability of your code. It makes it easier for others (or even yourself in the future) to understand the purpose of the values being used throughout the notebook.\n",
        "\n",
        "* **Code Consistency**: By defining constants, you ensure that specific values are consistently used across the notebook. If you need to change the value later, you only have to modify it in one place, reducing the risk of errors due to inconsistent values.\n",
        "\n",
        "* **Preventing Magic Numbers**: Magic numbers are hardcoded numeric values scattered throughout the code without any explanation or context. Using constants instead of magic numbers makes the code self-documenting and provides context for the values used.\n",
        "\n",
        "* **Flexibility**: If you need to change a value that is used in multiple places, having it defined as a constant allows you to change it once, and the change will automatically apply throughout the notebook.\n",
        "\n",
        "* **Easy Debugging**: When debugging the code, having constants allows you to quickly check the values being used in different parts of the notebook without having to search for where they are defined.\n",
        "\n",
        "* **Unit Testing**: If you plan to write unit tests for your code, using constants can make it easier to define test cases and assert expected results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "THpyIPqCzBue"
      },
      "outputs": [],
      "source": [
        "DATASETS_DIR = 'datasets/'\n",
        "URL = 'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'\n",
        "# DROP_COLS = ['boat','body','home.dest','ticket','name']\n",
        "DROP_COLS = ['boat','body','home.dest','ticket','name', 'cabin']\n",
        "RETRIEVED_DATA = 'raw-data.csv'\n",
        "\n",
        "\n",
        "SEED_SPLIT = 404\n",
        "TRAIN_DATA_FILE = f'{DATASETS_DIR}train.csv'\n",
        "TEST_DATA_FILE = f'{DATASETS_DIR}test.csv'\n",
        "\n",
        "\n",
        "TARGET = 'survived'\n",
        "# FEATURES = ['pclass','sex','age','sibsp','parch','fare','cabin','embarked','title']\n",
        "FEATURES = ['pclass','age','sibsp','parch','fare','embarked','title']\n",
        "NUMERICAL_VARS = ['pclass','age','sibsp','parch','fare']\n",
        "# CATEGORICAL_VARS = ['sex','cabin','embarked','title']\n",
        "CATEGORICAL_VARS = ['embarked','title']\n",
        "\n",
        "\n",
        "NUMERICAL_VARS_WITH_NA = ['age','fare']\n",
        "CATEGORICAL_VARS_WITH_NA = ['cabin','embarked']\n",
        "NUMERICAL_NA_NOT_ALLOWED = [var for var in NUMERICAL_VARS if var not in NUMERICAL_VARS_WITH_NA]\n",
        "CATEGORICAL_NA_NOT_ALLOWED = [var for var in CATEGORICAL_VARS if var not in CATEGORICAL_VARS_WITH_NA]\n",
        "\n",
        "\n",
        "SEED_MODEL = 404"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Functions\n",
        "Writing functions will help us for several things, for example:\n",
        "* **Modularity**: Functions allow you to break down complex problems into smaller, manageable pieces. Each function can handle a specific task, making the code easier to understand, test, and maintain. This concept is known as \"modularity.\"\n",
        "\n",
        "* **Reusability**: Once you define a function, you can use it multiple times throughout your code or even in other projects. This promotes code reuse and saves time since you don't have to rewrite the same logic each time you need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pkLHGa8FzBuf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory 'datasets/' created successfully.\n",
            "Data stored in datasets/raw-data.csv\n"
          ]
        }
      ],
      "source": [
        "def data_retrieval(url):\n",
        "\n",
        "    # Loading data from specific url\n",
        "    data = pd.read_csv(url)\n",
        "\n",
        "    # Uncovering missing data\n",
        "    data.replace('?', np.nan, inplace=True)\n",
        "    data['age'] = data['age'].astype('float')\n",
        "    data['fare'] = data['fare'].astype('float')\n",
        "\n",
        "    # helper function 1\n",
        "    def get_first_cabin(row):\n",
        "        try:\n",
        "            return row.split()[0]\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "\n",
        "    # helper function 2\n",
        "    def get_title(passenger):\n",
        "        line = passenger\n",
        "        if re.search('Mrs', line):\n",
        "            return 'Mrs'\n",
        "        elif re.search('Mr', line):\n",
        "            return 'Mr'\n",
        "        elif re.search('Miss', line):\n",
        "            return 'Miss'\n",
        "        elif re.search('Master', line):\n",
        "            return 'Master'\n",
        "        else:\n",
        "            return 'Other'\n",
        "\n",
        "    # Keep only one cabin | Extract the title from 'name'\n",
        "    data['cabin'] = data['cabin'].apply(get_first_cabin)\n",
        "    data['title'] = data['name'].apply(get_title)\n",
        "\n",
        "    # Droping irrelevant columns\n",
        "    data.drop(DROP_COLS, axis=1, inplace=True)\n",
        "\n",
        "    # Create directory if it does not exist\n",
        "    if not os.path.exists(DATASETS_DIR):\n",
        "        os.makedirs(DATASETS_DIR)\n",
        "        print(f\"Directory '{DATASETS_DIR}' created successfully.\")\n",
        "    else:\n",
        "        print(f\"Directory '{DATASETS_DIR}' already exists.\")\n",
        "    \n",
        "    # Save data to CSV file\n",
        "    data.to_csv(DATASETS_DIR + RETRIEVED_DATA, index=False)\n",
        "\n",
        "    return print('Data stored in {}'.format(DATASETS_DIR + RETRIEVED_DATA))\n",
        "\n",
        "data_retrieval(URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Transformers\n",
        "Custom transformers are really important if we want to have high-quality code, able to be maintaned, changed and be reused by other pieces of code.\n",
        "\n",
        "The following code is the migration from [3-create-convenient-classes.ipynb](../session-7/3-create-convenient-classes.ipynb) notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                        df.drop(TARGET, axis=1),\n",
        "                                                        df[TARGET],\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=404\n",
        "                                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MissingIndicator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to create indicator features for missing values in specified variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to create indicator features for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to create indicator features for.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            This method does not perform any actual training or fitting.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    missing_indicator = MissingIndicator(variables=['age', 'income'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('missing_indicator', missing_indicator),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the MissingIndicator transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to create indicator features for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        if not isinstance(variables, list):\n",
        "            self.variables = [variables]\n",
        "        else:\n",
        "            self.variables = variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        This method does not perform any actual training or fitting, as indicator features are created based on data.\n",
        "        It returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
        "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
        "\n",
        "        Returns:\n",
        "            self (MissingIndicator): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with additional indicator features for missing values.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[f'{var}_nan'] = X[var].isnull().astype(int)\n",
        "\n",
        "        return X\n",
        "    \n",
        "# create_missing_flag = MissingIndicator(variables=NUMERICAL_VARS)\n",
        "# X_train = create_missing_flag.transform(X_train)\n",
        "# X_test = create_missing_flag.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExtractLetters(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to extract letters from a specified variable.\n",
        "\n",
        "    Parameters:\n",
        "        None\n",
        "\n",
        "    Attributes:\n",
        "        variable (str): The name of the column (variable) from which letters will be extracted.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            This method does not perform any actual training or fitting.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Extracts letters from the specified variable and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    extractor = ExtractLetters()\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('extractor', extractor),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the ExtractLetters transformer.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.variable = 'cabin'\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        This method does not perform any actual training or fitting, as it is not necessary for this transformer.\n",
        "        It returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
        "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
        "\n",
        "        Returns:\n",
        "            self (ExtractLetters): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Extracts letters from the specified variable and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with letters extracted from the specified variable.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        X[self.variable] = X[self.variable].apply(lambda x: ''.join(re.findall(\"[a-zA-Z]+\", x)) if type(x)==str else x)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to impute missing values in categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to impute missing values for.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            This method does not perform any actual training or fitting.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Imputes missing values in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    imputer = CategoricalImputer(variables=['category1', 'category2'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('imputer', imputer),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the CategoricalImputer transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        This method does not perform any actual training or fitting, as imputation is based on data.\n",
        "        It returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
        "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
        "\n",
        "        Returns:\n",
        "            self (CategoricalImputer): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Imputes missing values in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with missing values imputed for the specified categorical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = X[var].fillna('Missing')\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to impute missing values in numerical variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to impute missing values for.\n",
        "        median_dict_ (dict): Dictionary to store the median values for each specified numerical variable during fitting.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Calculates the median values for the specified numerical variables from the training data.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Imputes missing values in the specified numerical variables using the median values and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    imputer = NumericalImputer(variables=['age', 'income'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('imputer', imputer),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the NumericalImputer transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Calculates the median values for the specified numerical variables from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (NumericalImputer): The transformer instance.\n",
        "        \"\"\"\n",
        "        self.median_dict_ = {}\n",
        "        for var in self.variables:\n",
        "            self.median_dict_[var] = X[var].median()\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Imputes missing values in the specified numerical variables using the median values and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with missing values imputed for the specified numerical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = X[var].fillna(self.median_dict_[var])\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RareLabelCategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to encode rare categories in categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "        tol (float, optional): The tolerance level to define rare categories.\n",
        "            Categories with a frequency lower than tol will be encoded as 'rare'.\n",
        "            Default is 0.05.\n",
        "        variables (list or str, optional): List of column names (variables) to encode rare categories for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        tol (float): The tolerance level to define rare categories.\n",
        "        variables (list): List of column names (variables) to encode rare categories for.\n",
        "        rare_labels_dict (dict): Dictionary to store the rare category labels for each specified categorical variable during fitting.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Calculates the rare category labels for the specified categorical variables from the training data.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Encodes rare categories in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    encoder = RareLabelCategoricalEncoder(tol=0.1, variables=['category1', 'category2'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('encoder', encoder),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, tol=0.05, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the RareLabelCategoricalEncoder transformer.\n",
        "\n",
        "        Parameters:\n",
        "            tol (float, optional): The tolerance level to define rare categories.\n",
        "                Categories with a frequency lower than tol will be encoded as 'rare'.\n",
        "                Default is 0.05.\n",
        "            variables (list or str, optional): List of column names (variables) to encode rare categories for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.tol = tol\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Calculates the rare category labels for the specified categorical variables from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (RareLabelCategoricalEncoder): The transformer instance.\n",
        "        \"\"\"\n",
        "        self.rare_labels_dict = {}\n",
        "        for var in self.variables:\n",
        "            t = pd.Series(X[var].value_counts() / float(X.shape[0]))\n",
        "            self.rare_labels_dict[var] = list(t[t<self.tol].index)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Encodes rare categories in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with rare categories encoded for the specified categorical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = np.where(X[var].isin(self.rare_labels_dict[var]), 'rare', X[var])\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to perform one-hot encoding for categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to perform one-hot encoding for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to perform one-hot encoding for.\n",
        "        dummies (list): List of column names representing the one-hot encoded dummy variables.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Calculates the one-hot encoded dummy variable columns for the specified categorical variables from the training data.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Performs one-hot encoding for the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    encoder = OneHotEncoder(variables=['category1', 'category2'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('encoder', encoder),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the OneHotEncoder transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to perform one-hot encoding for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Calculates the one-hot encoded dummy variable columns for the specified categorical variables from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (OneHotEncoder): The transformer instance.\n",
        "        \"\"\"\n",
        "        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Performs one-hot encoding for the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with one-hot encoded dummy variables for the specified categorical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        X = pd.concat([X, pd.get_dummies(X[self.variables], drop_first=True)], axis=1)\n",
        "        X.drop(self.variables, axis=1)\n",
        "\n",
        "        # Adding missing dummies, if any\n",
        "        missing_dummies = [var for var in self.dummies if var not in X.columns]\n",
        "        if len(missing_dummies) != 0:\n",
        "            for col in missing_dummies:\n",
        "                X[col] = 0\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.validation import check_array\n",
        "\n",
        "class OrderingFeatures(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to order features (columns) in the same order as they appeared in the training data.\n",
        "\n",
        "    Parameters:\n",
        "        None\n",
        "\n",
        "    Attributes:\n",
        "        ordered_features (pd.Index): Index of column names representing the order of features as they appeared in the training data.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Records the order of features from the training data and returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Reorders the features in the same order as they appeared in the training data and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    feature_orderer = OrderingFeatures()\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('feature_orderer', feature_orderer),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the OrderingFeatures transformer.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "        \"\"\"\n",
        "        return None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Records the order of features from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (OrderingFeatures): The transformer instance.\n",
        "        \"\"\"\n",
        "        X = check_array(X, accept_sparse=True)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.ordered_features = X.columns\n",
        "        elif isinstance(X, np.ndarray):\n",
        "            self.ordered_features = np.arange(X.shape[1])\n",
        "        else:\n",
        "            raise ValueError(\"Input X must be a pandas DataFrame or a numpy array.\")\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Reorders the features in the same order as they appeared in the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with features ordered as they appeared in the training data.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            print(X[self.ordered_features])\n",
        "            return X[self.ordered_features]\n",
        "        elif isinstance(X, np.ndarray):\n",
        "            print(X[:, self.ordered_features])\n",
        "            return X[:, self.ordered_features]\n",
        "        else:\n",
        "            raise ValueError(\"Input X must be a pandas DataFrame or a numpy array.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline\n",
        "The code below is a scikit-learn pipeline called titanic_pipeline, that is used for data preprocessing and modeling for a Titanic dataset classification task. Each step in the pipeline corresponds to a specific data transformation or modeling step.\n",
        "\n",
        "* **`MissingIndicator`**: This is a custom transformer that creates indicator features for missing values in numerical variables. It takes the NUMERICAL_VARS as input, which represents a list of numerical column names in the dataset.\n",
        "\n",
        "* **`ExtractLetters`**: This is a custom transformer that extracts letters from the 'cabin' variable. It aims to process the 'cabin' variable and retrieve only the alphabetical characters, discarding any numeric or special characters.\n",
        "\n",
        "* **`CategoricalImputer`**: This is a custom transformer that imputes missing values in categorical variables. It takes the CATEGORICAL_VARS_WITH_NA as input, which represents a list of categorical column names that may contain missing values. It fills in the missing values with the string 'Missing'.\n",
        "\n",
        "* **`NumericalImputer`**: This is a custom transformer that imputes missing values in numerical variables. It takes the NUMERICAL_VARS_WITH_NA as input, which represents a list of numerical column names that may contain missing values. It fills in the missing values with the median value of each respective variable.\n",
        "\n",
        "* **`RareLabelCategoricalEncoder`**: This is a custom transformer that encodes rare categories in categorical variables. It takes the CATEGORICAL_VARS as input, which represents a list of categorical column names to encode rare categories for. It identifies categories with a frequency lower than 5% (tolerance of 0.05) and encodes them as 'rare'.\n",
        "\n",
        "* **`OneHotEncoder`**: This is a custom transformer that performs one-hot encoding for categorical variables. It takes the CATEGORICAL_VARS as input, which represents a list of categorical column names to be one-hot encoded. It creates binary dummy variables for each category.\n",
        "\n",
        "* **`OrderingFeatures`**: This is a custom transformer that orders the features (columns) in the same order as they appeared in the training data. It ensures that the order of columns in the transformed dataset is consistent with the order in which the pipeline was trained.\n",
        "\n",
        "* **`MinMaxScaler`**: This step scales the numerical features to a specified range, typically between 0 and 1, using the Min-Max scaling technique.\n",
        "\n",
        "* **`LogisticRegression`**: This is the final modeling step in the pipeline. It fits a logistic regression model to the preprocessed dataset. The model is specified with hyperparameters C=0.0005, class_weight='balanced', and random_state=SEED_MODEL. The C parameter is the regularization strength, 'balanced' sets the class weights to be inversely proportional to the class frequencies to handle class imbalance, and random_state is used for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                        df.drop(TARGET, axis=1),\n",
        "                                                        df[TARGET],\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=404\n",
        "                                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Define the debug_print function to print DataFrame or array\n",
        "def debug_print(X):\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        print(X.head())  # Print the first few rows of the DataFrame\n",
        "    elif isinstance(X, np.ndarray):\n",
        "        print(X[:5])  # Print the first 5 rows of the array\n",
        "\n",
        "# Define the preprocessor for categorical variables\n",
        "categorical_preprocessor = Pipeline([\n",
        "    ('categorical_imputer', CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)),\n",
        "    ('rare_labels', RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)),\n",
        "    ('dummy_vars', OneHotEncoder(variables=CATEGORICAL_VARS))\n",
        "])\n",
        "\n",
        "# Define the preprocessor for numerical variables\n",
        "numerical_preprocessor = Pipeline([\n",
        "    ('missing_indicator', MissingIndicator(variables=NUMERICAL_VARS)),\n",
        "    # ('cabin_only_letter', ExtractLetters()),\n",
        "    ('median_imputation', NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)),\n",
        "    ('scaling', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Use ColumnTransformer to apply the different preprocessors to their respective columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('categorical', categorical_preprocessor, CATEGORICAL_VARS),\n",
        "        ('numerical', numerical_preprocessor, NUMERICAL_VARS)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Combine the preprocessor with the logistic regression model in the final pipeline\n",
        "titanic_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('aligning_feats', OrderingFeatures()),\n",
        "    ('log_reg', LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL))\n",
        "])\n",
        "\n",
        "# Debug each output after transformation\n",
        "X_train_transformed = titanic_pipeline['preprocessor'].fit_transform(X_train)\n",
        "debug_print(X_train_transformed)\n",
        "\n",
        "X_train_transformed = titanic_pipeline['aligning_feats'].fit_transform(X_train_transformed)\n",
        "debug_print(X_train_transformed)\n",
        "\n",
        "# Fit the model\n",
        "titanic_pipeline['log_reg'].fit(X_train_transformed, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhGa7W08zBuh"
      },
      "outputs": [],
      "source": [
        "titanic_pipeline = Pipeline(\n",
        "                              [\n",
        "                                ('missing_indicator', MissingIndicator(variables=NUMERICAL_VARS)),\n",
        "                                ('cabin_only_letter', ExtractLetters()),\n",
        "                                ('categorical_imputer', CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)),\n",
        "                                ('median_imputation', NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)),\n",
        "                                ('rare_labels', RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)),\n",
        "                                ('dummy_vars', OneHotEncoder(variables=CATEGORICAL_VARS)),\n",
        "                                ('aligning_feats', OrderingFeatures()),\n",
        "                                ('scaling', MinMaxScaler()),\n",
        "                                ('log_reg', LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL))\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZdT-Hh6zBuh"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#                                                         df.drop(TARGET, axis=1),\n",
        "#                                                         df[TARGET],\n",
        "#                                                         test_size=0.2,\n",
        "#                                                         random_state=404\n",
        "#                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>S</td>\n",
              "      <td>Mrs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8792</td>\n",
              "      <td>Q</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>2</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>136.7792</td>\n",
              "      <td>C</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>27.9000</td>\n",
              "      <td>S</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1047 rows  8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pclass     sex   age  sibsp  parch      fare embarked   title\n",
              "1162       3    male   NaN      0      0    7.7500        Q      Mr\n",
              "899        3  female  27.0      0      2   11.1333        S     Mrs\n",
              "1006       3  female   NaN      0      0    7.8792        Q    Miss\n",
              "228        1    male  18.0      1      0  108.9000        C      Mr\n",
              "573        2  female  27.0      0      0   10.5000        S    Miss\n",
              "...      ...     ...   ...    ...    ...       ...      ...     ...\n",
              "71         1    male  27.0      1      0  136.7792        C      Mr\n",
              "609        3    male  26.0      0      0    8.0500        S      Mr\n",
              "625        3  female  17.0      4      2    7.9250        S    Miss\n",
              "1012       3  female   NaN      0      0    7.7500        Q    Miss\n",
              "1206       3    male   4.0      3      2   27.9000        S  Master\n",
              "\n",
              "[1047 rows x 8 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# X_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8dZxc-6zBui"
      },
      "outputs": [],
      "source": [
        "# titanic_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fSyKuONzBui",
        "outputId": "b33acf23-818f-422c-db3b-300aab088ed6"
      },
      "outputs": [],
      "source": [
        "class_pred = titanic_pipeline.predict(X_test)\n",
        "proba_pred = titanic_pipeline.predict_proba(X_test)[:,1]\n",
        "print('test roc-auc : {}'.format(roc_auc_score(y_test, proba_pred)))\n",
        "print('test accuracy: {}'.format(accuracy_score(y_test, class_pred)))\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
