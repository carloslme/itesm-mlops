{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n",
        "In this notebook section, we will import the libraries needed to run this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9wFRz2IbzBua"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants\n",
        "In a Jupyter Notebook, creating constant variables can be important for several reasons:\n",
        "\n",
        "* **Readability and Maintainability**: Using constant variables with meaningful names can improve the readability of your code. It makes it easier for others (or even yourself in the future) to understand the purpose of the values being used throughout the notebook.\n",
        "\n",
        "* **Code Consistency**: By defining constants, you ensure that specific values are consistently used across the notebook. If you need to change the value later, you only have to modify it in one place, reducing the risk of errors due to inconsistent values.\n",
        "\n",
        "* **Preventing Magic Numbers**: Magic numbers are hardcoded numeric values scattered throughout the code without any explanation or context. Using constants instead of magic numbers makes the code self-documenting and provides context for the values used.\n",
        "\n",
        "* **Flexibility**: If you need to change a value that is used in multiple places, having it defined as a constant allows you to change it once, and the change will automatically apply throughout the notebook.\n",
        "\n",
        "* **Easy Debugging**: When debugging the code, having constants allows you to quickly check the values being used in different parts of the notebook without having to search for where they are defined.\n",
        "\n",
        "* **Unit Testing**: If you plan to write unit tests for your code, using constants can make it easier to define test cases and assert expected results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "THpyIPqCzBue"
      },
      "outputs": [],
      "source": [
        "DATASETS_DIR = './datasets/'\n",
        "URL = 'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'\n",
        "DROP_COLS = ['boat','body','home.dest','ticket','name']\n",
        "RETRIEVED_DATA = 'raw-data.csv'\n",
        "\n",
        "\n",
        "SEED_SPLIT = 404\n",
        "TRAIN_DATA_FILE = DATASETS_DIR + 'train.csv'\n",
        "TEST_DATA_FILE  = DATASETS_DIR + 'test.csv'\n",
        "\n",
        "\n",
        "TARGET = 'survived'\n",
        "FEATURES = ['pclass','sex','age','sibsp','parch','fare','cabin','embarked','title']\n",
        "NUMERICAL_VARS = ['pclass','age','sibsp','parch','fare']\n",
        "CATEGORICAL_VARS = ['sex','cabin','embarked','title']\n",
        "\n",
        "\n",
        "NUMERICAL_VARS_WITH_NA = ['age','fare']\n",
        "CATEGORICAL_VARS_WITH_NA = ['cabin','embarked']\n",
        "NUMERICAL_NA_NOT_ALLOWED = [var for var in NUMERICAL_VARS if var not in NUMERICAL_VARS_WITH_NA]\n",
        "CATEGORICAL_NA_NOT_ALLOWED = [var for var in CATEGORICAL_VARS if var not in CATEGORICAL_VARS_WITH_NA]\n",
        "\n",
        "\n",
        "SEED_MODEL = 404\n",
        "\n",
        "SELECTED_FEATURES = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin', 'embarked',\n",
        "       'title', 'pclass_nan', 'age_nan', 'sibsp_nan', 'parch_nan', 'fare_nan',\n",
        "       'sex_male', 'cabin_Missing', 'cabin_rare', 'embarked_Q', 'embarked_S',\n",
        "       'title_Mr', 'title_Mrs', 'title_rare']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Functions\n",
        "Writing functions will help us for several things, for example:\n",
        "* **Modularity**: Functions allow you to break down complex problems into smaller, manageable pieces. Each function can handle a specific task, making the code easier to understand, test, and maintain. This concept is known as \"modularity.\"\n",
        "\n",
        "* **Reusability**: Once you define a function, you can use it multiple times throughout your code or even in other projects. This promotes code reuse and saves time since you don't have to rewrite the same logic each time you need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pkLHGa8FzBuf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory './datasets/' already exists.\n",
            "Data stored in ./datasets/raw-data.csv\n"
          ]
        }
      ],
      "source": [
        "def data_retrieval(url):\n",
        "\n",
        "    # Loading data from specific url\n",
        "    data = pd.read_csv(url)\n",
        "\n",
        "    # Uncovering missing data\n",
        "    data.replace('?', np.nan, inplace=True)\n",
        "    data['age'] = data['age'].astype('float')\n",
        "    data['fare'] = data['fare'].astype('float')\n",
        "\n",
        "    # helper function 1\n",
        "    def get_first_cabin(row):\n",
        "        try:\n",
        "            return row.split()[0]\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "\n",
        "    # helper function 2\n",
        "    def get_title(passenger):\n",
        "        line = passenger\n",
        "        if re.search('Mrs', line):\n",
        "            return 'Mrs'\n",
        "        elif re.search('Mr', line):\n",
        "            return 'Mr'\n",
        "        elif re.search('Miss', line):\n",
        "            return 'Miss'\n",
        "        elif re.search('Master', line):\n",
        "            return 'Master'\n",
        "        else:\n",
        "            return 'Other'\n",
        "\n",
        "    # Keep only one cabin | Extract the title from 'name'\n",
        "    data['cabin'] = data['cabin'].apply(get_first_cabin)\n",
        "    data['title'] = data['name'].apply(get_title)\n",
        "\n",
        "    # Droping irrelevant columns\n",
        "    data.drop(DROP_COLS, axis=1, inplace=True)\n",
        "\n",
        "    # Create directory if it does not exist\n",
        "    if not os.path.exists(DATASETS_DIR):\n",
        "        os.makedirs(DATASETS_DIR)\n",
        "        print(f\"Directory '{DATASETS_DIR}' created successfully.\")\n",
        "    else:\n",
        "        print(f\"Directory '{DATASETS_DIR}' already exists.\")\n",
        "    \n",
        "    # Save data to CSV file\n",
        "    data.to_csv(DATASETS_DIR + RETRIEVED_DATA, index=False)\n",
        "\n",
        "    return print('Data stored in {}'.format(DATASETS_DIR + RETRIEVED_DATA))\n",
        "\n",
        "data_retrieval(URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Transformers\n",
        "Custom transformers are really important if we want to have high-quality code, able to be maintaned, changed and be reused by other pieces of code.\n",
        "\n",
        "The following code is the migration from [3-create-convenient-classes.ipynb](../session-7/3-create-convenient-classes.ipynb) notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MissingIndicator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to create indicator features for missing values in specified variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to create indicator features for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to create indicator features for.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            This method does not perform any actual training or fitting.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    missing_indicator = MissingIndicator(variables=['age', 'income'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('missing_indicator', missing_indicator),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the MissingIndicator transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to create indicator features for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        if not isinstance(variables, list):\n",
        "            self.variables = [variables]\n",
        "        else:\n",
        "            self.variables = variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        This method does not perform any actual training or fitting, as indicator features are created based on data.\n",
        "        It returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
        "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
        "\n",
        "        Returns:\n",
        "            self (MissingIndicator): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with additional indicator features for missing values.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[f'{var}_nan'] = X[var].isnull().astype(int)\n",
        "\n",
        "        return X\n",
        "    \n",
        "# create_missing_flag = MissingIndicator(variables=NUMERICAL_VARS)\n",
        "# X_train = create_missing_flag.transform(X_train)\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExtractLetters(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to extract letters from a specified variable.\n",
        "\n",
        "    Parameters:\n",
        "        None\n",
        "\n",
        "    Attributes:\n",
        "        variable (str): The name of the column (variable) from which letters will be extracted.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            This method does not perform any actual training or fitting.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Extracts letters from the specified variable and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    extractor = ExtractLetters()\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('extractor', extractor),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the ExtractLetters transformer.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.variable = 'cabin'\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        This method does not perform any actual training or fitting, as it is not necessary for this transformer.\n",
        "        It returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
        "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
        "\n",
        "        Returns:\n",
        "            self (ExtractLetters): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Extracts letters from the specified variable and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with letters extracted from the specified variable.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        X[self.variable] = X[self.variable].apply(lambda x: ''.join(re.findall(\"[a-zA-Z]+\", x)) if type(x)==str else x)\n",
        "        return X\n",
        "    \n",
        "# extractor = ExtractLetters()\n",
        "# X_train = extractor.transform(X_train)\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to impute missing values in categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to impute missing values for.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            This method does not perform any actual training or fitting.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Imputes missing values in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    imputer = CategoricalImputer(variables=['category1', 'category2'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('imputer', imputer),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the CategoricalImputer transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        This method does not perform any actual training or fitting, as imputation is based on data.\n",
        "        It returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
        "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
        "\n",
        "        Returns:\n",
        "            self (CategoricalImputer): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Imputes missing values in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with missing values imputed for the specified categorical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = X[var].fillna('Missing')\n",
        "        return X\n",
        "    \n",
        "# imputer = CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)\n",
        "# X_train = imputer.transform(X_train)\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to impute missing values in numerical variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to impute missing values for.\n",
        "        median_dict_ (dict): Dictionary to store the median values for each specified numerical variable during fitting.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Calculates the median values for the specified numerical variables from the training data.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Imputes missing values in the specified numerical variables using the median values and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    imputer = NumericalImputer(variables=['age', 'income'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('imputer', imputer),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the NumericalImputer transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to impute missing values for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Calculates the median values for the specified numerical variables from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (NumericalImputer): The transformer instance.\n",
        "        \"\"\"\n",
        "        self.median_dict = {}\n",
        "        for var in self.variables:\n",
        "            self.median_dict[var] = X[var].median()\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Imputes missing values in the specified numerical variables using the median values and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with missing values imputed for the specified numerical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = X[var].fillna(self.median_dict[var])\n",
        "        return X\n",
        "    \n",
        "# print(NUMERICAL_VARS_WITH_NA)\n",
        "# median_imputation = NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)\n",
        "# median_imputation.fit(X_train)\n",
        "# X_train = median_imputation.transform(X_train)\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RareLabelCategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to encode rare categories in categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "        tol (float, optional): The tolerance level to define rare categories.\n",
        "            Categories with a frequency lower than tol will be encoded as 'rare'.\n",
        "            Default is 0.05.\n",
        "        variables (list or str, optional): List of column names (variables) to encode rare categories for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        tol (float): The tolerance level to define rare categories.\n",
        "        variables (list): List of column names (variables) to encode rare categories for.\n",
        "        rare_labels_dict (dict): Dictionary to store the rare category labels for each specified categorical variable during fitting.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Calculates the rare category labels for the specified categorical variables from the training data.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Encodes rare categories in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    encoder = RareLabelCategoricalEncoder(tol=0.1, variables=['category1', 'category2'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('encoder', encoder),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, tol=0.05, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the RareLabelCategoricalEncoder transformer.\n",
        "\n",
        "        Parameters:\n",
        "            tol (float, optional): The tolerance level to define rare categories.\n",
        "                Categories with a frequency lower than tol will be encoded as 'rare'.\n",
        "                Default is 0.05.\n",
        "            variables (list or str, optional): List of column names (variables) to encode rare categories for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.tol = tol\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Calculates the rare category labels for the specified categorical variables from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (RareLabelCategoricalEncoder): The transformer instance.\n",
        "        \"\"\"\n",
        "        self.rare_labels_dict = {}\n",
        "        for var in self.variables:\n",
        "            t = pd.Series(X[var].value_counts() / float(X.shape[0]))\n",
        "            self.rare_labels_dict[var] = list(t[t<self.tol].index)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Encodes rare categories in the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with rare categories encoded for the specified categorical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = np.where(X[var].isin(self.rare_labels_dict[var]), 'rare', X[var])\n",
        "        return X\n",
        "    \n",
        "# print(CATEGORICAL_VARS)\n",
        "# encoder = RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)\n",
        "# encoder.fit(X_train)\n",
        "# X_train = encoder.transform(X_train)\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to perform one-hot encoding for categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "        variables (list or str, optional): List of column names (variables) to perform one-hot encoding for.\n",
        "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "\n",
        "    Attributes:\n",
        "        variables (list): List of column names (variables) to perform one-hot encoding for.\n",
        "        dummies (list): List of column names representing the one-hot encoded dummy variables.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Calculates the one-hot encoded dummy variable columns for the specified categorical variables from the training data.\n",
        "            It returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Performs one-hot encoding for the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    encoder = OneHotEncoder(variables=['category1', 'category2'])\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('encoder', encoder),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, variables=None):\n",
        "        \"\"\"\n",
        "        Initialize the OneHotEncoder transformer.\n",
        "\n",
        "        Parameters:\n",
        "            variables (list or str, optional): List of column names (variables) to perform one-hot encoding for.\n",
        "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
        "        \"\"\"\n",
        "        self.variables = [variables] if not isinstance(variables, list) else variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Calculates the one-hot encoded dummy variable columns for the specified categorical variables from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (OneHotEncoder): The transformer instance.\n",
        "        \"\"\"\n",
        "        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Performs one-hot encoding for the specified categorical variables and returns the modified DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with one-hot encoded dummy variables for the specified categorical variables.\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "        X = pd.concat([X, pd.get_dummies(X[self.variables], drop_first=True)], axis=1)\n",
        "        X.drop(self.variables, axis=1)\n",
        "\n",
        "        # Adding missing dummies, if any\n",
        "        missing_dummies = [var for var in self.dummies if var not in X.columns]\n",
        "        if len(missing_dummies) != 0:\n",
        "            for col in missing_dummies:\n",
        "                X[col] = 0\n",
        "\n",
        "        return X\n",
        "    \n",
        "    \n",
        "# print(CATEGORICAL_VARS)\n",
        "# one_encoder = OneHotEncoder(variables=CATEGORICAL_VARS)\n",
        "# one_encoder.fit(X_train)\n",
        "# X_train = one_encoder.transform(X_train)\n",
        "# X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to select specific features (columns) from a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        feature_names (list or array-like): List of column names to select as features from the input DataFrame.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Placeholder method that returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Selects and returns the specified features (columns) from the input DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Define the feature names to be selected\n",
        "    selected_features = ['feature1', 'feature2', 'feature3']\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    feature_selector = FeatureSelector(feature_names=selected_features)\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('feature_selector', feature_selector),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_names):\n",
        "        \"\"\"\n",
        "        Initialize the FeatureSelector transformer.\n",
        "\n",
        "        Parameters:\n",
        "            feature_names (list or array-like): List of column names to select as features from the input DataFrame.\n",
        "        \"\"\"\n",
        "        self.feature_names = feature_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Placeholder method that returns the transformer instance itself.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (FeatureSelector): The transformer instance.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Selects and returns the specified features (columns) from the input DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_selected (pd.DataFrame): DataFrame containing only the specified features (columns).\n",
        "        \"\"\"\n",
        "        return X[self.feature_names]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OrderingFeatures(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom scikit-learn transformer to order features (columns) in the same order as they appeared in the training data.\n",
        "\n",
        "    Parameters:\n",
        "        None\n",
        "\n",
        "    Attributes:\n",
        "        ordered_features (pd.Index): Index of column names representing the order of features as they appeared in the training data.\n",
        "\n",
        "    Methods:\n",
        "        fit(X, y=None):\n",
        "            Records the order of features from the training data and returns the transformer instance itself.\n",
        "\n",
        "        transform(X):\n",
        "            Reorders the features in the same order as they appeared in the training data and returns the modified DataFrame.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # Instantiate the custom transformer\n",
        "    feature_orderer = OrderingFeatures()\n",
        "\n",
        "    # Define the pipeline with the custom transformer\n",
        "    pipeline = Pipeline([\n",
        "        ('feature_orderer', feature_orderer),\n",
        "        # Other pipeline steps...\n",
        "    ])\n",
        "\n",
        "    # Fit and transform the data using the pipeline\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the OrderingFeatures transformer.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "        \"\"\"\n",
        "        return None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Records the order of features from the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            self (OrderingFeatures): The transformer instance.\n",
        "        \"\"\"\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.ordered_features = X.columns\n",
        "            print(self.ordered_features)\n",
        "        elif isinstance(X, np.ndarray):\n",
        "            self.ordered_features = np.arange(X.shape[1])\n",
        "        else:\n",
        "            raise ValueError(\"Input X must be a pandas DataFrame or a numpy array.\")\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Reorders the features in the same order as they appeared in the training data.\n",
        "\n",
        "        Parameters:\n",
        "            X (pd.DataFrame): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "            X_transformed (pd.DataFrame): Transformed DataFrame with features ordered as they appeared in the training data.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # print(X[self.ordered_features])\n",
        "            # print(\"return df\")\n",
        "            DROP_COLS_AFTER = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin', 'embarked','title']\n",
        "            X[self.ordered_features]\n",
        "            X.drop(DROP_COLS_AFTER, axis=1, inplace=True)\n",
        "            return X\n",
        "        elif isinstance(X, np.ndarray):\n",
        "            # print(\"return np\")\n",
        "            return X[:, self.ordered_features]\n",
        "        else:\n",
        "            raise ValueError(\"Input X must be a pandas DataFrame or a numpy array.\")\n",
        "\n",
        "\n",
        "# feature_orderer = OrderingFeatures()\n",
        "# feature_orderer.fit(X_train)\n",
        "# df = feature_orderer.transform(X_train)\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline\n",
        "The code below is a scikit-learn pipeline called titanic_pipeline, that is used for data preprocessing and modeling for a Titanic dataset classification task. Each step in the pipeline corresponds to a specific data transformation or modeling step.\n",
        "\n",
        "* **`MissingIndicator`**: This is a custom transformer that creates indicator features for missing values in numerical variables. It takes the NUMERICAL_VARS as input, which represents a list of numerical column names in the dataset.\n",
        "\n",
        "* **`ExtractLetters`**: This is a custom transformer that extracts letters from the 'cabin' variable. It aims to process the 'cabin' variable and retrieve only the alphabetical characters, discarding any numeric or special characters.\n",
        "\n",
        "* **`CategoricalImputer`**: This is a custom transformer that imputes missing values in categorical variables. It takes the CATEGORICAL_VARS_WITH_NA as input, which represents a list of categorical column names that may contain missing values. It fills in the missing values with the string 'Missing'.\n",
        "\n",
        "* **`NumericalImputer`**: This is a custom transformer that imputes missing values in numerical variables. It takes the NUMERICAL_VARS_WITH_NA as input, which represents a list of numerical column names that may contain missing values. It fills in the missing values with the median value of each respective variable.\n",
        "\n",
        "* **`RareLabelCategoricalEncoder`**: This is a custom transformer that encodes rare categories in categorical variables. It takes the CATEGORICAL_VARS as input, which represents a list of categorical column names to encode rare categories for. It identifies categories with a frequency lower than 5% (tolerance of 0.05) and encodes them as 'rare'.\n",
        "\n",
        "* **`OneHotEncoder`**: This is a custom transformer that performs one-hot encoding for categorical variables. It takes the CATEGORICAL_VARS as input, which represents a list of categorical column names to be one-hot encoded. It creates binary dummy variables for each category.\n",
        "\n",
        "* **`OrderingFeatures`**: This is a custom transformer that orders the features (columns) in the same order as they appeared in the training data. It ensures that the order of columns in the transformed dataset is consistent with the order in which the pipeline was trained.\n",
        "\n",
        "* **`MinMaxScaler`**: This step scales the numerical features to a specified range, typically between 0 and 1, using the Min-Max scaling technique.\n",
        "\n",
        "* **`LogisticRegression`**: This is the final modeling step in the pipeline. It fits a logistic regression model to the preprocessed dataset. The model is specified with hyperparameters C=0.0005, class_weight='balanced', and random_state=SEED_MODEL. The C parameter is the regularization strength, 'balanced' sets the class weights to be inversely proportional to the class frequencies to handle class imbalance, and random_state is used for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                        df.drop(TARGET, axis=1),\n",
        "                                                        df[TARGET],\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=404\n",
        "                                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NhGa7W08zBuh"
      },
      "outputs": [],
      "source": [
        "transformations_pipeline = Pipeline(\n",
        "                              [\n",
        "                                ('missing_indicator', MissingIndicator(variables=NUMERICAL_VARS)),\n",
        "                                ('cabin_only_letter', ExtractLetters()),\n",
        "                                ('categorical_imputer', CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)),\n",
        "                                ('median_imputation', NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)),\n",
        "                                ('rare_labels', RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)),\n",
        "                                ('dummy_vars', OneHotEncoder(variables=CATEGORICAL_VARS)),\n",
        "                                ('feature_selector', FeatureSelector(SELECTED_FEATURES)),\n",
        "                                ('aligning_feats', OrderingFeatures()),\n",
        "                                ('scaling', MinMaxScaler()),\n",
        "                              ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;missing_indicator&#x27;,\n",
              "                 MissingIndicator(variables=[&#x27;pclass&#x27;, &#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;,\n",
              "                                             &#x27;fare&#x27;])),\n",
              "                (&#x27;cabin_only_letter&#x27;, ExtractLetters()),\n",
              "                (&#x27;categorical_imputer&#x27;,\n",
              "                 CategoricalImputer(variables=[&#x27;cabin&#x27;, &#x27;embarked&#x27;])),\n",
              "                (&#x27;median_imputation&#x27;,\n",
              "                 NumericalImputer(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])),\n",
              "                (&#x27;rare_labels&#x27;,\n",
              "                 RareLabelCategoricalEncoder(variables=[&#x27;sex&#x27;, &#x27;cabi...\n",
              "                (&#x27;feature_selector&#x27;,\n",
              "                 FeatureSelector(feature_names=[&#x27;pclass&#x27;, &#x27;sex&#x27;, &#x27;age&#x27;, &#x27;sibsp&#x27;,\n",
              "                                                &#x27;parch&#x27;, &#x27;fare&#x27;, &#x27;cabin&#x27;,\n",
              "                                                &#x27;embarked&#x27;, &#x27;title&#x27;,\n",
              "                                                &#x27;pclass_nan&#x27;, &#x27;age_nan&#x27;,\n",
              "                                                &#x27;sibsp_nan&#x27;, &#x27;parch_nan&#x27;,\n",
              "                                                &#x27;fare_nan&#x27;, &#x27;sex_male&#x27;,\n",
              "                                                &#x27;cabin_Missing&#x27;, &#x27;cabin_rare&#x27;,\n",
              "                                                &#x27;embarked_Q&#x27;, &#x27;embarked_S&#x27;,\n",
              "                                                &#x27;title_Mr&#x27;, &#x27;title_Mrs&#x27;,\n",
              "                                                &#x27;title_rare&#x27;])),\n",
              "                (&#x27;aligning_feats&#x27;, OrderingFeatures()),\n",
              "                (&#x27;scaling&#x27;, MinMaxScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;missing_indicator&#x27;,\n",
              "                 MissingIndicator(variables=[&#x27;pclass&#x27;, &#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;,\n",
              "                                             &#x27;fare&#x27;])),\n",
              "                (&#x27;cabin_only_letter&#x27;, ExtractLetters()),\n",
              "                (&#x27;categorical_imputer&#x27;,\n",
              "                 CategoricalImputer(variables=[&#x27;cabin&#x27;, &#x27;embarked&#x27;])),\n",
              "                (&#x27;median_imputation&#x27;,\n",
              "                 NumericalImputer(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])),\n",
              "                (&#x27;rare_labels&#x27;,\n",
              "                 RareLabelCategoricalEncoder(variables=[&#x27;sex&#x27;, &#x27;cabi...\n",
              "                (&#x27;feature_selector&#x27;,\n",
              "                 FeatureSelector(feature_names=[&#x27;pclass&#x27;, &#x27;sex&#x27;, &#x27;age&#x27;, &#x27;sibsp&#x27;,\n",
              "                                                &#x27;parch&#x27;, &#x27;fare&#x27;, &#x27;cabin&#x27;,\n",
              "                                                &#x27;embarked&#x27;, &#x27;title&#x27;,\n",
              "                                                &#x27;pclass_nan&#x27;, &#x27;age_nan&#x27;,\n",
              "                                                &#x27;sibsp_nan&#x27;, &#x27;parch_nan&#x27;,\n",
              "                                                &#x27;fare_nan&#x27;, &#x27;sex_male&#x27;,\n",
              "                                                &#x27;cabin_Missing&#x27;, &#x27;cabin_rare&#x27;,\n",
              "                                                &#x27;embarked_Q&#x27;, &#x27;embarked_S&#x27;,\n",
              "                                                &#x27;title_Mr&#x27;, &#x27;title_Mrs&#x27;,\n",
              "                                                &#x27;title_rare&#x27;])),\n",
              "                (&#x27;aligning_feats&#x27;, OrderingFeatures()),\n",
              "                (&#x27;scaling&#x27;, MinMaxScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MissingIndicator</label><div class=\"sk-toggleable__content\"><pre>MissingIndicator(variables=[&#x27;pclass&#x27;, &#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtractLetters</label><div class=\"sk-toggleable__content\"><pre>ExtractLetters()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;cabin&#x27;, &#x27;embarked&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NumericalImputer</label><div class=\"sk-toggleable__content\"><pre>NumericalImputer(variables=[&#x27;age&#x27;, &#x27;fare&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelCategoricalEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelCategoricalEncoder(variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;, &#x27;title&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(variables=[&#x27;sex&#x27;, &#x27;cabin&#x27;, &#x27;embarked&#x27;, &#x27;title&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(feature_names=[&#x27;pclass&#x27;, &#x27;sex&#x27;, &#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;,\n",
              "                               &#x27;cabin&#x27;, &#x27;embarked&#x27;, &#x27;title&#x27;, &#x27;pclass_nan&#x27;,\n",
              "                               &#x27;age_nan&#x27;, &#x27;sibsp_nan&#x27;, &#x27;parch_nan&#x27;, &#x27;fare_nan&#x27;,\n",
              "                               &#x27;sex_male&#x27;, &#x27;cabin_Missing&#x27;, &#x27;cabin_rare&#x27;,\n",
              "                               &#x27;embarked_Q&#x27;, &#x27;embarked_S&#x27;, &#x27;title_Mr&#x27;,\n",
              "                               &#x27;title_Mrs&#x27;, &#x27;title_rare&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrderingFeatures</label><div class=\"sk-toggleable__content\"><pre>OrderingFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('missing_indicator',\n",
              "                 MissingIndicator(variables=['pclass', 'age', 'sibsp', 'parch',\n",
              "                                             'fare'])),\n",
              "                ('cabin_only_letter', ExtractLetters()),\n",
              "                ('categorical_imputer',\n",
              "                 CategoricalImputer(variables=['cabin', 'embarked'])),\n",
              "                ('median_imputation',\n",
              "                 NumericalImputer(variables=['age', 'fare'])),\n",
              "                ('rare_labels',\n",
              "                 RareLabelCategoricalEncoder(variables=['sex', 'cabi...\n",
              "                ('feature_selector',\n",
              "                 FeatureSelector(feature_names=['pclass', 'sex', 'age', 'sibsp',\n",
              "                                                'parch', 'fare', 'cabin',\n",
              "                                                'embarked', 'title',\n",
              "                                                'pclass_nan', 'age_nan',\n",
              "                                                'sibsp_nan', 'parch_nan',\n",
              "                                                'fare_nan', 'sex_male',\n",
              "                                                'cabin_Missing', 'cabin_rare',\n",
              "                                                'embarked_Q', 'embarked_S',\n",
              "                                                'title_Mr', 'title_Mrs',\n",
              "                                                'title_rare'])),\n",
              "                ('aligning_feats', OrderingFeatures()),\n",
              "                ('scaling', MinMaxScaler())])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformations_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin', 'embarked',\n",
            "       'title', 'pclass_nan', 'age_nan', 'sibsp_nan', 'parch_nan', 'fare_nan',\n",
            "       'sex_male', 'cabin_Missing', 'cabin_rare', 'embarked_Q', 'embarked_S',\n",
            "       'title_Mr', 'title_Mrs', 'title_rare'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "X_train = transformations_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.0005, class_weight=&#x27;balanced&#x27;, random_state=404)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.0005, class_weight=&#x27;balanced&#x27;, random_state=404)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=0.0005, class_weight='balanced', random_state=404)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logistic_regression = LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL)\n",
        "logistic_regression.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin', 'embarked',\n",
            "       'title', 'pclass_nan', 'age_nan', 'sibsp_nan', 'parch_nan', 'fare_nan',\n",
            "       'sex_male', 'cabin_Missing', 'cabin_rare', 'embarked_Q', 'embarked_S',\n",
            "       'title_Mr', 'title_Mrs', 'title_rare'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "X_test = transformations_pipeline.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(262, 13)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = logistic_regression.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4fSyKuONzBui",
        "outputId": "b33acf23-818f-422c-db3b-300aab088ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test roc-auc : 0.8152286743603835\n",
            "test accuracy: 0.7748091603053435\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class_pred = logistic_regression.predict(X_test)\n",
        "proba_pred = logistic_regression.predict_proba(X_test)[:,1]\n",
        "print(f'test roc-auc : {roc_auc_score(y_test, proba_pred)}')\n",
        "print(f'test accuracy: {accuracy_score(y_test, class_pred)}')\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Persisting the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['trained_models/logistic_regression_output.pkl']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "TRAINED_MODEL_DIR = 'trained_models/'\n",
        "PIPELINE_NAME = 'logistic_regression'\n",
        "PIPELINE_SAVE_FILE = f'{PIPELINE_NAME}_output.pkl'\n",
        "\n",
        "# Save the model using joblib\n",
        "save_path = TRAINED_MODEL_DIR + PIPELINE_SAVE_FILE\n",
        "joblib.dump(logistic_regression, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Basic input validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "input_data = X_test.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Making predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n"
          ]
        }
      ],
      "source": [
        "# Sample single input data in dictionary format\n",
        "single_input_data = {\n",
        "    'pclass': 6,\n",
        "    'sex': 'female',\n",
        "    'age': 60,\n",
        "    'sibsp': 1,\n",
        "    'parch': 0,\n",
        "    'fare': 8,\n",
        "    'cabin': 'B5',\n",
        "    'embarked': 'B',\n",
        "    'title': 'Miss'\n",
        "}\n",
        "# Convert the single input data to a DataFrame\n",
        "single_input_df = pd.DataFrame([single_input_data])\n",
        "\n",
        "# Preprocess the single input data using the transformations_pipeline\n",
        "preprocessed_single_input = transformations_pipeline.transform(single_input_df)\n",
        "\n",
        "# Load the model using joblib\n",
        "trained_model = joblib.load(save_path)\n",
        "\n",
        "# Predict the target value using the loaded model\n",
        "predicted_value = trained_model.predict(preprocessed_single_input)\n",
        "\n",
        "print(predicted_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extra\n",
        "Use this code to debug the Custom Transformer pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# # Define the debug_print function to print DataFrame or array\n",
        "# def debug_print(X):\n",
        "#     if isinstance(X, pd.DataFrame):\n",
        "#         print(X.head())  # Print the first few rows of the DataFrame\n",
        "#     elif isinstance(X, np.ndarray):\n",
        "#         print(X[:5])  # Print the first 5 rows of the array\n",
        "        \n",
        "\n",
        "# # Define the preprocessor for categorical variables\n",
        "# categorical_preprocessor = Pipeline([\n",
        "#     ('categorical_imputer', CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)),\n",
        "#     ('rare_labels', RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)),\n",
        "#     ('dummy_vars', OneHotEncoder(variables=CATEGORICAL_VARS))\n",
        "# ])\n",
        "\n",
        "# # Define the preprocessor for numerical variables\n",
        "# numerical_preprocessor = Pipeline([\n",
        "#     ('missing_indicator', MissingIndicator(variables=NUMERICAL_VARS)),\n",
        "#     # ('cabin_only_letter', ExtractLetters()),\n",
        "#     ('median_imputation', NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)),\n",
        "#     ('scaling', MinMaxScaler())\n",
        "# ])\n",
        "\n",
        "# # Use ColumnTransformer to apply the different preprocessors to their respective columns\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('categorical', categorical_preprocessor, CATEGORICAL_VARS),\n",
        "#         ('numerical', numerical_preprocessor, NUMERICAL_VARS)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# # Combine the preprocessor with the logistic regression model in the final pipeline\n",
        "# titanic_pipeline = Pipeline([\n",
        "#     ('preprocessor', preprocessor),\n",
        "#     ('aligning_feats', OrderingFeatures()),\n",
        "#     ('log_reg', LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL))\n",
        "# ])\n",
        "\n",
        "# # Debug each output after transformation\n",
        "# X_train_transformed = titanic_pipeline['preprocessor'].fit_transform(X_train)\n",
        "# debug_print(X_train_transformed)\n",
        "\n",
        "# # Fit the model\n",
        "# titanic_pipeline['log_reg'].fit(X_train_transformed, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
