{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAH3KGTrtS-8"
      },
      "source": [
        "# Introduction\n",
        "The objective of this notebook is to show how to develop concept tests for unit tests and integration.\n",
        "\n",
        "It is divided into the definition of functions, then the tests showing examples of bad practices, good practices with parameterization, brands, and finally integration tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pji7dRu04o4O"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwrhN3Dz4rlL",
        "outputId": "d2bd3464-4d06-46ad-a12a-ccb7570b965f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytest\n",
            "  Using cached pytest-7.4.0-py3-none-any.whl (323 kB)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Using cached pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
            "Collecting iniconfig\n",
            "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting tomli>=1.0.0\n",
            "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from pytest) (23.1)\n",
            "Collecting exceptiongroup>=1.0.0rc8\n",
            "  Using cached exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tomli, pluggy, iniconfig, exceptiongroup, pytest\n",
            "Successfully installed exceptiongroup-1.1.2 iniconfig-2.0.0 pluggy-1.2.0 pytest-7.4.0 tomli-2.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI1CrtpV5Cjl",
        "outputId": "90527ccd-17a1-475a-90b8-d5c63de16ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pytest 7.4.0\n"
          ]
        }
      ],
      "source": [
        "!pytest --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkF7ARxE0GpL"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1EheZDe0OUu"
      },
      "source": [
        "### Functions to try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KlF2wBG0Ew4",
        "outputId": "d516ad53-3ca1-4636-b08d-f783cb2b130a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CarlosLopezMejia\n"
          ]
        }
      ],
      "source": [
        "def procesar_nombre(nombre):\n",
        "    if isinstance(nombre, str):\n",
        "      return nombre.capitalize()\n",
        "    return \"Error nombre\"\n",
        "\n",
        "def procesar_apellido_paterno(apellido_p):\n",
        "    if isinstance(apellido_p, str):\n",
        "      return apellido_p.capitalize()\n",
        "    return \"Error Apellido Paterno\"\n",
        "\n",
        "def procesar_apellido_materno(apellido_m):\n",
        "    if isinstance(apellido_m, str):\n",
        "      return apellido_m.capitalize()\n",
        "    return \"Error Apellido Materno\"\n",
        "\n",
        "n = procesar_nombre(\"carlos\")\n",
        "ap = procesar_apellido_paterno(\"lopez\")\n",
        "am = procesar_apellido_materno(\"mejia\")\n",
        "print(n + ap + am)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzXicMFz0REO"
      },
      "source": [
        "### Functions to save on file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI3D4Oy1uWLB"
      },
      "source": [
        "The \"magic command\" of ipython `%%writefile file.py` is used to create a file with the content of the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJS3N75b0UAC",
        "outputId": "95e148f8-dc1a-4986-cb1f-065a4538cbde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing funciones.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile funciones.py\n",
        "def procesar_nombre(nombre):\n",
        "    if isinstance(nombre, str):\n",
        "      return nombre.capitalize()\n",
        "    return \"Error nombre\"\n",
        "\n",
        "def procesar_apellido_paterno(apellido_p):\n",
        "    if isinstance(apellido_p, str):\n",
        "      return apellido_p.capitalize()\n",
        "    return \"Error Apellido Paterno\"\n",
        "\n",
        "def procesar_apellido_materno(apellido_m):\n",
        "    if isinstance(apellido_m, str):\n",
        "      return apellido_m.capitalize()\n",
        "    return \"Error Apellido Materno\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljqLY8F70KBA"
      },
      "source": [
        "# Evidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2qmMGkV00Nk"
      },
      "source": [
        "### Bad practices: multiple tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyjBOsyu0Jmz",
        "outputId": "a1244791-ef0f-4949-f7be-6a795c90277c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_malas_practicas.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_malas_practicas.py\n",
        "import funciones as tf\n",
        "\n",
        "# Pruebas para el nombre\n",
        "def test_procesar_nombre():\n",
        "  assert tf.procesar_nombre(\"carlos\") == \"Carlos\"\n",
        "\n",
        "def test_procesar_nombre_2():\n",
        "  assert tf.procesar_nombre(\"MiGuel\") == \"Miguel\"\n",
        "\n",
        "def test_procesar_nombre_3():\n",
        "  assert tf.procesar_nombre(\"iVAN\") == \"Ivan\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP1ktC3j1U8-",
        "outputId": "88719b1f-496c-49d4-ae01-d8b385ecfa31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform darwin -- Python 3.10.12, pytest-7.4.0, pluggy-1.2.0 -- /Users/carlos/Downloads/ejemplo/venv/bin/python3.10\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /Users/carlos/Downloads/ejemplo\n",
            "configfile: pytest.ini\n",
            "collected 3 items                                                              \u001b[0m\n",
            "\n",
            "test_malas_practicas.py::test_procesar_nombre \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 33%]\u001b[0m\n",
            "test_malas_practicas.py::test_procesar_nombre_2 \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 66%]\u001b[0m\n",
            "test_malas_practicas.py::test_procesar_nombre_3 \u001b[32mPASSED\u001b[0m\u001b[32m                   [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest test_malas_practicas.py -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEzwV8Ad1yQJ"
      },
      "source": [
        "### Good practices: parameterized tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcX5P5Zv1xH-",
        "outputId": "3a8bc255-cc06-4659-aedb-02c9943755f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_buenas_practicas.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_buenas_practicas.py\n",
        "import funciones as tf\n",
        "import pytest\n",
        "\n",
        "# Pruebas para el nombre\n",
        "def obtener_datos_test_nombre():\n",
        "        return [(\"carlos\",\"Carlos\"), (\"MiGuel\", \"Miguel\"), (\"iVAN\", \"Ivan\")]\n",
        "\n",
        "@pytest.mark.parametrize('nombre, esperado', obtener_datos_test_nombre())\n",
        "def test_nombre_parametrize(nombre, esperado):\n",
        "        assert tf.procesar_nombre(nombre) == esperado\n",
        "\n",
        "# Pruebas para el apellido paterno\n",
        "def obtener_datos_test_ap():\n",
        "        return [(\"LOPEZ\",\"Lopez\"), (\"EspiNOZA\", \"Espinoza\"), (\"SmiTH\", \"Smith\")]\n",
        "\n",
        "@pytest.mark.parametrize('ap, esperado', obtener_datos_test_ap())\n",
        "def test_ap_parametrize(ap, esperado):\n",
        "        assert tf.procesar_apellido_paterno(ap) == esperado\n",
        "\n",
        "# Pruebas para el apellido materno\n",
        "def obtener_datos_test_am():\n",
        "        return [(\"ferrer\",\"Ferrer\"), (\"SILVa\", \"Silva\"), (\"PalafoX\", \"Palafox\")]\n",
        "\n",
        "@pytest.mark.parametrize('am, esperado', obtener_datos_test_am())\n",
        "def test_am_parametrize(am, esperado):\n",
        "        assert tf.procesar_apellido_paterno(am) == esperado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNTPVe1p1xH_",
        "outputId": "8d550719-1a2e-4998-d7e9-26c9a1ba778e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform darwin -- Python 3.10.12, pytest-7.4.0, pluggy-1.2.0 -- /Users/carlos/Downloads/ejemplo/venv/bin/python3.10\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /Users/carlos/Downloads/ejemplo\n",
            "configfile: pytest.ini\n",
            "collected 9 items                                                              \u001b[0m\n",
            "\n",
            "test_buenas_practicas.py::test_nombre_parametrize[carlos-Carlos] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 11%]\u001b[0m\n",
            "test_buenas_practicas.py::test_nombre_parametrize[MiGuel-Miguel] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 22%]\u001b[0m\n",
            "test_buenas_practicas.py::test_nombre_parametrize[iVAN-Ivan] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 33%]\u001b[0m\n",
            "test_buenas_practicas.py::test_ap_parametrize[LOPEZ-Lopez] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 44%]\u001b[0m\n",
            "test_buenas_practicas.py::test_ap_parametrize[EspiNOZA-Espinoza] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n",
            "test_buenas_practicas.py::test_ap_parametrize[SmiTH-Smith] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
            "test_buenas_practicas.py::test_am_parametrize[ferrer-Ferrer] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 77%]\u001b[0m\n",
            "test_buenas_practicas.py::test_am_parametrize[SILVa-Silva] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 88%]\u001b[0m\n",
            "test_buenas_practicas.py::test_am_parametrize[PalafoX-Palafox] \u001b[32mPASSED\u001b[0m\u001b[32m    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest test_buenas_practicas.py -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZrGsdkR3sKx"
      },
      "source": [
        "### Marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV8eI8M02bmE",
        "outputId": "66141132-1ac3-4d6c-b550-a987aa388889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_marks.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_marks.py\n",
        "import funciones as tf\n",
        "import pytest\n",
        "\n",
        "@pytest.mark.skip(reason=\"Check www.google.com. There is no way to try this now. \")\n",
        "def test_calcular_curp():\n",
        "    pass\n",
        "\n",
        "#   xfail\n",
        "@pytest.mark.xfail\n",
        "def test_nombre_falla():\n",
        "    assert tf.procesar_nombre(12) == \"Doce\"\n",
        "\n",
        "#   Escribir un marcador personal\n",
        "@pytest.mark.mi_marca\n",
        "def test_mi_marca():\n",
        "    assert tf.procesar_nombre(\"jorgE\") == \"Jorge\"\n",
        "\n",
        "@pytest.mark.xfail\n",
        "def test_procesar_nombre_2():\n",
        "  assert tf.procesar_nombre(\"MiGuel\") == \"Miguel\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqg_L1hqJU6X"
      },
      "source": [
        "We have to register our markers in a `pytest.ini`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap0UH_DwIj02",
        "outputId": "3dd8a227-97b6-4000-a5d9-66820056c520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting pytest.ini\n"
          ]
        }
      ],
      "source": [
        "%%writefile pytest.ini\n",
        "[pytest]\n",
        "markers =\n",
        "    mi_marca: Ejemplo de marcador\n",
        "    web_mark: Otro ejemplo de marcador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzNFVhAE4vNV",
        "outputId": "bc1701c0-1860-47c8-c7f7-e5c80d97ef40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform darwin -- Python 3.10.12, pytest-7.4.0, pluggy-1.2.0 -- /Users/carlos/Downloads/ejemplo/venv/bin/python3.10\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /Users/carlos/Downloads/ejemplo\n",
            "configfile: pytest.ini\n",
            "collected 4 items                                                              \u001b[0m\n",
            "\n",
            "test_marks.py::test_calcular_curp \u001b[33mSKIPPED\u001b[0m (Check www.google.com. The...)\u001b[32m [ 25%]\u001b[0m\n",
            "test_marks.py::test_nombre_falla \u001b[33mXFAIL\u001b[0m\u001b[32m                                   [ 50%]\u001b[0m\n",
            "test_marks.py::test_mi_marca \u001b[32mPASSED\u001b[0m\u001b[32m                                      [ 75%]\u001b[0m\n",
            "test_marks.py::test_procesar_nombre_2 \u001b[33mXPASS\u001b[0m\u001b[33m                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[33m============== \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m1 xfailed\u001b[0m, \u001b[33m\u001b[1m1 xpassed\u001b[0m\u001b[33m in 0.05s\u001b[0m\u001b[33m ==============\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest test_marks.py -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60PShOCQF_G3",
        "outputId": "417eeb51-5aab-47bb-9404-63c35e633e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m@pytest.mark.mi_marca:\u001b[0m Ejemplo de marcador\n",
            "\n",
            "\u001b[1m@pytest.mark.web_mark:\u001b[0m Otro ejemplo de marcador\n",
            "\n",
            "\u001b[1m@pytest.mark.filterwarnings(warning):\u001b[0m add a warning filter to the given test. see https://docs.pytest.org/en/stable/how-to/capture-warnings.html#pytest-mark-filterwarnings \n",
            "\n",
            "\u001b[1m@pytest.mark.skip(reason=None):\u001b[0m skip the given test function with an optional reason. Example: skip(reason=\"no way of currently testing this\") skips the test.\n",
            "\n",
            "\u001b[1m@pytest.mark.skipif(condition, ..., *, reason=...):\u001b[0m skip the given test function if any of the conditions evaluate to True. Example: skipif(sys.platform == 'win32') skips the test if we are on the win32 platform. See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-skipif\n",
            "\n",
            "\u001b[1m@pytest.mark.xfail(condition, ..., *, reason=..., run=True, raises=None, strict=xfail_strict):\u001b[0m mark the test function as an expected failure if any of the conditions evaluate to True. Optionally specify a reason for better reporting and run=False if you don't even want to execute the test function. If only specific exception(s) are expected, you can list them in raises, and if the test fails in other ways, it will be reported as a true failure. See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-xfail\n",
            "\n",
            "\u001b[1m@pytest.mark.parametrize(argnames, argvalues):\u001b[0m call a test function multiple times passing in different arguments in turn. argvalues generally needs to be a list of values if argnames specifies only one name or a list of tuples of values if argnames specifies multiple names. Example: @parametrize('arg1', [1,2]) would lead to two calls of the decorated test function, one with arg1=1 and another with arg1=2.see https://docs.pytest.org/en/stable/how-to/parametrize.html for more info and examples.\n",
            "\n",
            "\u001b[1m@pytest.mark.usefixtures(fixturename1, fixturename2, ...):\u001b[0m mark tests as needing all of the specified fixtures. see https://docs.pytest.org/en/stable/explanation/fixtures.html#usefixtures \n",
            "\n",
            "\u001b[1m@pytest.mark.tryfirst:\u001b[0m mark a hook implementation function such that the plugin machinery will try to call it first/as early as possible. DEPRECATED, use @pytest.hookimpl(tryfirst=True) instead.\n",
            "\n",
            "\u001b[1m@pytest.mark.trylast:\u001b[0m mark a hook implementation function such that the plugin machinery will try to call it last/as late as possible. DEPRECATED, use @pytest.hookimpl(trylast=True) instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pytest --markers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mnxXkLO7uZL"
      },
      "source": [
        "# Integration testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TkGRmUF5tzw",
        "outputId": "6643af44-5f4e-4d1b-a1bd-e93473f91557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_integracion.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_integracion.py\n",
        "from funciones import procesar_nombre\n",
        "from funciones import procesar_apellido_paterno\n",
        "from funciones import procesar_apellido_materno\n",
        "import pytest\n",
        "\n",
        "def obtener_datos_test_integracion():\n",
        "        return [(\"carlos\",\"LOPEZ\", \"meJIa\", \"Carlos Lopez Mejia\"),\n",
        "                (\"ivan\", \"huERTA\", \"CoroNA\", \"Ivan Huerta Corona\")]\n",
        "\n",
        "@pytest.mark.parametrize('nombre, ap, am, esperado', obtener_datos_test_integracion())\n",
        "def test_divide_parametrize(nombre, ap, am, esperado):\n",
        "        assert procesar_nombre(nombre) + \" \" + procesar_apellido_paterno(ap) + \" \" + procesar_apellido_materno(am) == esperado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4q12Ggg_B1c",
        "outputId": "f41c658c-e95a-40dd-d4a0-ac9d9d1ba0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform darwin -- Python 3.10.12, pytest-7.4.0, pluggy-1.2.0 -- /Users/carlos/Downloads/ejemplo/venv/bin/python3.10\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /Users/carlos/Downloads/ejemplo\n",
            "configfile: pytest.ini\n",
            "collected 2 items                                                              \u001b[0m\n",
            "\n",
            "test_integracion.py::test_divide_parametrize[carlos-LOPEZ-meJIa-Carlos Lopez Mejia] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "test_integracion.py::test_divide_parametrize[ivan-huERTA-CoroNA-Ivan Huerta Corona] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest test_integracion.py -v"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
